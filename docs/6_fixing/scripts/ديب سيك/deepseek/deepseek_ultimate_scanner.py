#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
===============================================================================
ğŸ”’ DEEP SEEK ULTIMATE SECURITY SCANNER v5.0 - Nexus Complete Suite
===============================================================================

Ù†Ø¸Ø§Ù… Ø§Ù„ÙØ­Øµ Ø§Ù„Ø£Ù…Ù†ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„ Ø§Ù„Ø°ÙŠ ÙŠØºØ·ÙŠ Ø¬Ù…ÙŠØ¹ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø£Ù…Ø§Ù† Ø§Ù„Ù€36 Ù„Ø¹Ø§Ù… 2025

Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©:
âœ… ØªØºØ·ÙŠØ© ÙƒØ§Ù…Ù„Ø© Ù„Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø£Ù…Ù†ÙŠØ© Ø§Ù„Ù€36
âœ… ØªÙƒØ§Ù…Ù„ Ù…Ø¹ DeepSeek Ø§Ù„Ù…Ø­Ù„ÙŠ ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ
âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¬Ù‡Ø§Ø² (GPUØŒ RAMØŒ CPU)
âœ… ÙØ­Øµ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª ÙˆØ§Ù„Ø·Ø¨Ù‚Ø§Øª
âœ… ØªÙ‚Ø§Ø±ÙŠØ± Ù…ÙØµÙ„Ø© Ù…Ù‚Ø³Ù…Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£Ù‡Ù…ÙŠØ©
âœ… Ø¯Ø§Ø´ Ø¨ÙˆØ±Ø¯ ØªÙØ§Ø¹Ù„ÙŠ Ù„Ù„ØªØ­ÙƒÙ… ÙˆØ§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©
âœ… Ù†Ø¸Ø§Ù… Ø¥ØµÙ„Ø§Ø­ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø°ÙƒÙŠ
âœ… Ø¯Ø¹Ù… Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© ÙˆØ§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©

Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù…ØºØ·Ø§Ø©:
1-31: Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø£Ù…Ø§Ù† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (OWASPØŒ CWEØŒ NISTØŒ GDPR)
32: Ø£Ù…Ø§Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (AI/LLM Security)
33: Ø£Ù…Ø§Ù† Web3 ÙˆØ§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
34: Ø§Ù„ØªØ´ÙÙŠØ± Ø§Ù„Ù…Ù‚Ø§ÙˆÙ… Ù„Ù„ÙƒÙ… (Quantum-Safe)
35: DevSecOps Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
36: Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙƒÙØ§Ø¡Ø© ÙˆØ§Ù„Ø£Ø¯Ø§Ø¡

Ø§Ù„Ù…Ø¤Ù„Ù: GitHub Copilot & Nexus Security Team
Ø§Ù„ØªØ§Ø±ÙŠØ®: 22 Ø³Ø¨ØªÙ…Ø¨Ø± 2025
Ø§Ù„Ø¥ØµØ¯Ø§Ø±: 5.0.0
===============================================================================
"""

import os
import sys
import json
import time
import hashlib
import subprocess
import threading
import concurrent.futures
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
import logging
import re
import ast
import importlib.util

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±ÙŠØ© Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    psutil = None
    HAS_PSUTIL = False

try:
    import GPUtil
    HAS_GPUTIL = True
except ImportError:
    GPUtil = None
    HAS_GPUTIL = False

try:
    import requests
    HAS_REQUESTS = True
except ImportError:
    requests = None
    HAS_REQUESTS = False

try:
    import torch
    HAS_TORCH = True
except ImportError:
    torch = None
    HAS_TORCH = False

try:
    from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
    HAS_TRANSFORMERS = True
except ImportError:
    pipeline = None
    AutoTokenizer = None
    AutoModelForCausalLM = None
    HAS_TRANSFORMERS = False
try:
    import cpuinfo
    HAS_CPUINFO = True
except ImportError:
    cpuinfo = None
    HAS_CPUINFO = False

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±ÙŠØ© Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    psutil = None
    HAS_PSUTIL = False

try:
    import GPUtil
    HAS_GPUTIL = True
except ImportError:
    GPUtil = None
    HAS_GPUTIL = False

try:
    import requests
    HAS_REQUESTS = True
except ImportError:
    requests = None
    HAS_REQUESTS = False

try:
    import torch
    HAS_TORCH = True
except ImportError:
    torch = None
    HAS_TORCH = False

try:
    from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
    HAS_TRANSFORMERS = True
except ImportError:
    pipeline = None
    AutoTokenizer = None
    AutoModelForCausalLM = None
    HAS_TRANSFORMERS = False

try:
    import cpuinfo
    HAS_CPUINFO = True
except ImportError:
    cpuinfo = None
    HAS_CPUINFO = False

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
try:
    import yaml
    import toml
    import jinja2
    import numpy as np
    import torch
    import transformers
    from cryptography.hazmat.primitives import hashes
    from cryptography.hazmat.primitives.asymmetric import rsa, padding
    import web3
    from eth_account import Account
except ImportError as e:
    print(f"ØªØ­Ø°ÙŠØ±: Ù…ÙƒØªØ¨Ø© Ù…ØªÙ‚Ø¯Ù…Ø© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©: {e}")

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©
try:
    from ai_analyzer import LocalDeepSeekIntegration
    from deepseek_fixer import DeepSeekFixer
    from simple_scan import SimpleScanner
except ImportError:
    print("ØªØ­Ø°ÙŠØ±: Ù…ÙƒÙˆÙ†Ø§Øª Ù…Ø­Ù„ÙŠØ© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©")

@dataclass
class SecurityFinding:
    """ÙØ¦Ø© Ù„ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø£Ù…Ù†ÙŠØ©"""
    rule_id: str
    severity: str
    category: str
    title: str
    description: str
    file_path: str
    line_number: int
    code_snippet: str
    recommendation: str
    cwe_id: str = ""
    owasp_id: str = ""
    confidence: float = 0.0
    ai_analysis: Dict[str, Any] = None
    fix_suggestion: str = ""
    quantum_safe: bool = False
    web3_compatible: bool = False
    efficiency_score: float = 0.0

@dataclass
class ScanResult:
    """ÙØ¦Ø© Ù„ØªÙ…Ø«ÙŠÙ„ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙØ­Øµ"""
    scan_id: str
    timestamp: datetime
    target_path: str
    total_files: int
    scanned_files: int
    findings: List[SecurityFinding]
    summary: Dict[str, Any]
    performance_metrics: Dict[str, Any]
    ai_insights: Dict[str, Any]
    quantum_assessment: Dict[str, Any]
    web3_analysis: Dict[str, Any]
    efficiency_report: Dict[str, Any]

class DeepSeekUltimateScanner:
    """Ø§Ù„Ù…Ø§Ø³Ø­ Ø§Ù„Ø£Ù…Ù†ÙŠ Ø§Ù„Ø´Ø§Ù…Ù„ Ù…Ø¹ ØªÙƒØ§Ù…Ù„ DeepSeek"""

    def __init__(self, config_path: str = None):
        self.config_path = config_path or "security-config.json"
        self.load_config()

        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
        self.setup_directories()

        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        self.setup_logging()

        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
        self.initialize_components()

        # ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø£Ù…Ø§Ù† Ø§Ù„Ù€36
        self.load_security_rules()

        # Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¬Ù‡Ø§Ø²
        self.setup_hardware_resources()

    def load_config(self):
        """ØªØ­Ù…ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
        default_config = {
            "deepseek": {
                "local_path": "~/deepseek/deepseek-coder",
                "api_url": "http://localhost:5000/api/v1",
                "timeout": 30,
                "max_retries": 3
            },
            "scanning": {
                "max_workers": 4,
                "batch_size": 100,
                "timeout": 300,
                "max_file_size": 10485760,  # 10MB
                "excluded_paths": [".git", "node_modules", "__pycache__", ".venv"],
                "included_extensions": [".py", ".js", ".ts", ".jsx", ".tsx", ".java", ".php", ".go", ".rs", ".cpp", ".c", ".h"]
            },
            "reporting": {
                "output_formats": ["json", "html", "markdown", "pdf"],
                "max_report_size": 50000000,  # 50MB
                "chunk_size": 1000,  # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±
                "ai_review_chunks": 500
            },
            "hardware": {
                "use_gpu": True,
                "gpu_memory_limit": 0.8,
                "cpu_threads": None,
                "memory_limit": 0.9
            },
            "ai": {
                "model_cache_dir": "./ai_cache",
                "analysis_timeout": 60,
                "confidence_threshold": 0.7
            }
        }

        if os.path.exists(self.config_path):
            with open(self.config_path, 'r', encoding='utf-8') as f:
                user_config = json.load(f)
                self.config = self.deep_merge(default_config, user_config)
        else:
            self.config = default_config

    def deep_merge(self, base: dict, update: dict) -> dict:
        """Ø¯Ù…Ø¬ Ø§Ù„Ù‚ÙˆØ§Ù…ÙŠØ³ Ø¨Ø¹Ù…Ù‚"""
        for key, value in update.items():
            if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                self.deep_merge(base[key], value)
            else:
                base[key] = value
        return base

    def setup_directories(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
        base_dir = Path(__file__).parent

        self.directories = {
            "reports": base_dir / "reports",
            "errors": base_dir / "reports" / "errors_detected",
            "fixes": base_dir / "reports" / "fix_plans",
            "repairs": base_dir / "reports" / "repair_reports",
            "backups": base_dir / "backups",
            "cache": base_dir / "cache",
            "logs": base_dir / "logs",
            "ai_cache": base_dir / "ai_cache",
            "temp": base_dir / "temp"
        }

        for dir_path in self.directories.values():
            dir_path.mkdir(parents=True, exist_ok=True)

    def setup_logging(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„"""
        log_file = self.directories["logs"] / f"scanner_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )

        self.logger = logging.getLogger("DeepSeekScanner")

    def initialize_components(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
        try:
            self.deepseek = LocalDeepSeekIntegration(self.config["deepseek"]["local_path"])
            self.logger.info("ØªÙ… ØªÙ‡ÙŠØ¦Ø© ØªÙƒØ§Ù…Ù„ DeepSeek Ø§Ù„Ù…Ø­Ù„ÙŠ")
        except Exception as e:
            self.logger.warning(f"ÙØ´Ù„ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© DeepSeek: {e}")
            self.deepseek = None

        try:
            self.fixer = DeepSeekFixer()
            self.logger.info("ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ø¥ØµÙ„Ø§Ø­")
        except Exception as e:
            self.logger.warning(f"ÙØ´Ù„ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ø¥ØµÙ„Ø§Ø­: {e}")
            self.fixer = None

        try:
            self.simple_scanner = SimpleScanner()
            self.logger.info("ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø§Ø³Ø­ Ø§Ù„Ø¨Ø³ÙŠØ·")
        except Exception as e:
            self.logger.warning(f"ÙØ´Ù„ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø§Ø³Ø­ Ø§Ù„Ø¨Ø³ÙŠØ·: {e}")
            self.simple_scanner = None

    def load_security_rules(self):
        """ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø£Ù…Ø§Ù† Ø§Ù„Ù€36"""
        self.security_rules = {
            # Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© 1-31
            "code_injection": {
                "patterns": [r"eval\s*\(", r"Function\s*\(", r"setTimeout\s*\([^,)]*\)", r"setInterval\s*\([^,)]*\)"],
                "severity": "CRITICAL",
                "category": "Injection",
                "cwe": "CWE-94",
                "description": "Code Injection Vulnerabilities"
            },
            "path_traversal": {
                "patterns": [r"\.\./", r"\.\.\\", r"path\s*\+", r"join\s*\([^)]*userInput"],
                "severity": "HIGH",
                "category": "Path Traversal",
                "cwe": "CWE-22",
                "description": "Path Traversal Attacks"
            },
            "xss": {
                "patterns": [r"innerHTML\s*=", r"outerHTML\s*=", r"document\.write\s*\(", r"dangerouslySetInnerHTML"],
                "severity": "HIGH",
                "category": "XSS",
                "cwe": "CWE-79",
                "description": "Cross-Site Scripting"
            },
            "sql_injection": {
                "patterns": [r"SELECT.*\+", r"INSERT.*\+", r"UPDATE.*\+", r"DELETE.*\+", r"query\s*\([^)]*\+[^)]*\)"],
                "severity": "CRITICAL",
                "category": "Injection",
                "cwe": "CWE-89",
                "description": "SQL Injection"
            },
            "weak_crypto": {
                "patterns": [r"md5\s*\(", r"sha1\s*\(", r"des\s*\(", r"rc4\s*\("],
                "severity": "MEDIUM",
                "category": "Cryptography",
                "cwe": "CWE-327",
                "description": "Weak Cryptographic Algorithms"
            },
            "hardcoded_secrets": {
                "patterns": [r"password\s*=\s*['\"][^'\"]*['\"]", r"api_key\s*=\s*['\"][^'\"]*['\"]", r"secret\s*=\s*['\"][^'\"]*['\"]"],
                "severity": "HIGH",
                "category": "Secrets",
                "cwe": "CWE-798",
                "description": "Hardcoded Secrets"
            },
            "command_injection": {
                "patterns": [r"exec\s*\(", r"system\s*\(", r"popen\s*\(", r"subprocess\.call\s*\([^)]*\+[^)]*\)"],
                "severity": "CRITICAL",
                "category": "Injection",
                "cwe": "CWE-78",
                "description": "Command Injection"
            },
            "insecure_random": {
                "patterns": [r"random\s*\.", r"Math\.random\s*\(", r"rand\s*\("],
                "severity": "MEDIUM",
                "category": "Cryptography",
                "cwe": "CWE-338",
                "description": "Insecure Random Number Generation"
            },
            "buffer_overflow": {
                "patterns": [r"strcpy\s*\(", r"strcat\s*\(", r"sprintf\s*\(", r"gets\s*\("],
                "severity": "HIGH",
                "category": "Buffer",
                "cwe": "CWE-119",
                "description": "Buffer Overflow Vulnerabilities"
            },
            "race_condition": {
                "patterns": [r"check.*use", r"time.*check", r"access.*modify"],
                "severity": "MEDIUM",
                "category": "Concurrency",
                "cwe": "CWE-362",
                "description": "Race Condition Vulnerabilities"
            },
            # Ù…Ø¹Ø§ÙŠÙŠØ± TypeScript/JavaScript
            "typescript_strict": {
                "patterns": [r"any\s*:\s*any", r"// @ts-ignore", r"as\s+any"],
                "severity": "LOW",
                "category": "TypeScript",
                "description": "TypeScript Strict Mode Violations"
            },
            "error_handling": {
                "patterns": [r"catch\s*\([^)]*\)\s*\{\s*\}", r"throw\s+new\s+Error\s*\("],
                "severity": "MEDIUM",
                "category": "Error Handling",
                "description": "Poor Error Handling"
            },
            "async_await": {
                "patterns": [r"\.then\s*\(", r"Promise\s*\.\s*(all|race|resolve|reject)"],
                "severity": "LOW",
                "category": "Async",
                "description": "Async/Await Usage Issues"
            },
            # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø£Ù…Ø§Ù† Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
            "auth_bypass": {
                "patterns": [r"admin\s*=\s*true", r"role\s*=\s*['\"]admin['\"]", r"bypass.*auth"],
                "severity": "CRITICAL",
                "category": "Authentication",
                "cwe": "CWE-285",
                "description": "Authentication Bypass"
            },
            "input_validation": {
                "patterns": [r"req\.body", r"req\.query", r"req\.params"],
                "severity": "MEDIUM",
                "category": "Validation",
                "cwe": "CWE-20",
                "description": "Missing Input Validation"
            },
            "logging_security": {
                "patterns": [r"console\.log\s*\([^)]*password[^)]*\)", r"console\.log\s*\([^)]*token[^)]*\)"],
                "severity": "MEDIUM",
                "category": "Logging",
                "cwe": "CWE-532",
                "description": "Sensitive Data in Logs"
            },
            # Ù…Ø¹Ø§ÙŠÙŠØ± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            "db_optimization": {
                "patterns": [r"SELECT\s*\*", r"N\+1.*query", r"no.*index"],
                "severity": "LOW",
                "category": "Database",
                "description": "Database Performance Issues"
            },
            "caching_strategy": {
                "patterns": [r"cache.*miss", r"no.*cache", r"cache.*invalid"],
                "severity": "LOW",
                "category": "Caching",
                "description": "Poor Caching Strategy"
            },
            # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ÙˆÙŠØ¨
            "csp_headers": {
                "patterns": [r"Content-Security-Policy", r"X-Frame-Options", r"X-Content-Type-Options"],
                "severity": "MEDIUM",
                "category": "Headers",
                "cwe": "CWE-693",
                "description": "Missing Security Headers"
            },
            "react_security": {
                "patterns": [r"dangerouslySetInnerHTML", r"eval\s*\(", r"Function\s*\("],
                "severity": "HIGH",
                "category": "React",
                "description": "React Security Issues"
            },
            # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
            "security_testing": {
                "patterns": [r"test.*security", r"security.*test"],
                "severity": "LOW",
                "category": "Testing",
                "description": "Security Testing Coverage"
            },
            "performance_testing": {
                "patterns": [r"benchmark", r"performance.*test", r"load.*test"],
                "severity": "LOW",
                "category": "Performance",
                "description": "Performance Testing"
            },
            # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¬ÙˆØ¯Ø©
            "code_quality": {
                "patterns": [r"TODO", r"FIXME", r"HACK", r"console\.log"],
                "severity": "LOW",
                "category": "Quality",
                "description": "Code Quality Issues"
            },
            "maintainability": {
                "patterns": [r"function.*\{[^}]*\}", r"class.*\{[^}]*\}"],
                "severity": "LOW",
                "category": "Maintainability",
                "description": "Code Maintainability"
            },
            "reliability": {
                "patterns": [r"catch.*Exception", r"try.*catch"],
                "severity": "MEDIUM",
                "category": "Reliability",
                "description": "Error Handling Reliability"
            },
            "efficiency": {
                "patterns": [r"O\(n\^2\)", r"nested.*loop", r"inefficient.*algorithm"],
                "severity": "LOW",
                "category": "Efficiency",
                "description": "Algorithm Efficiency"
            },
            "test_coverage": {
                "patterns": [r"test.*coverage", r"coverage.*report"],
                "severity": "LOW",
                "category": "Testing",
                "description": "Test Coverage Analysis"
            },
            # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (32)
            "ai_security": {
                "patterns": [r"prompt.*injection", r"model.*poisoning", r"adversarial.*input", r"ai.*backdoor"],
                "severity": "HIGH",
                "category": "AI Security",
                "cwe": "CWE-AI-001",
                "description": "AI/LLM Security Vulnerabilities"
            },
            # Ù…Ø¹Ø§ÙŠÙŠØ± Web3 (33)
            "web3_security": {
                "patterns": [r"reentrancy", r"access.*control", r"integer.*overflow", r"unchecked.*call"],
                "severity": "CRITICAL",
                "category": "Web3 Security",
                "description": "Smart Contract Vulnerabilities"
            },
            # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ÙƒÙ… (34)
            "quantum_crypto": {
                "patterns": [r"rsa.*1024", r"ecdsa.*p256", r"aes.*128", r"sha.*256"],
                "severity": "MEDIUM",
                "category": "Quantum Security",
                "description": "Quantum-Vulnerable Cryptography"
            },
            # Ù…Ø¹Ø§ÙŠÙŠØ± DevSecOps (35)
            "devsecops": {
                "patterns": [r"no.*pipeline", r"no.*security.*scan", r"no.*sast", r"no.*dast"],
                "severity": "MEDIUM",
                "category": "DevSecOps",
                "description": "DevSecOps Pipeline Issues"
            },
            # Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙƒÙØ§Ø¡Ø© (36)
            "efficiency_metrics": {
                "patterns": [r"complexity.*high", r"maintainability.*low", r"performance.*poor"],
                "severity": "LOW",
                "category": "Efficiency",
                "description": "Code Efficiency Metrics"
            }
        }

    def setup_hardware_resources(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¬Ù‡Ø§Ø²"""
        self.hardware = {
            "cpu": {
                "cores": psutil.cpu_count(logical=False) if HAS_PSUTIL else 0,
                "threads": psutil.cpu_count(logical=True) if HAS_PSUTIL else 0,
                "info": HAS_CPUINFO and cpuinfo.get_cpu_info() if HAS_CPUINFO else {}
            },
            "memory": {
                "total": psutil.virtual_memory().total if HAS_PSUTIL else 0,
                "available": psutil.virtual_memory().available if HAS_PSUTIL else 0
            },
            "gpu": []
        }

        try:
            if HAS_GPUTIL:
                gpus = GPUtil.getGPUs()
                for gpu in gpus:
                    self.hardware["gpu"].append({
                        "name": gpu.name,
                        "memory_total": gpu.memoryTotal,
                        "memory_free": gpu.memoryFree,
                        "temperature": gpu.temperature
                    })
        except:
            self.logger.warning("GPU information not available")

        self.logger.info(f"Hardware resources detected: CPU={self.hardware['cpu']['cores']} cores, RAM={self.hardware['memory']['total']//(1024**3) if self.hardware['memory']['total'] > 0 else 0}GB, GPU={len(self.hardware['gpu'])} devices")

    def scan_project(self, target_path: str, scan_type: str = "full") -> ScanResult:
        """ÙØ­Øµ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„"""
        start_time = time.time()
        scan_id = hashlib.md5(f"{target_path}_{datetime.now().isoformat()}".encode()).hexdigest()[:8]

        self.logger.info(f"Ø¨Ø¯Ø¡ Ø§Ù„ÙØ­Øµ Ø§Ù„Ø´Ø§Ù…Ù„: {scan_id}")

        # Ø¬Ù…Ø¹ Ø§Ù„Ù…Ù„ÙØ§Øª
        files_to_scan = self.collect_files(target_path)

        # ÙØ­Øµ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª
        findings = []
        performance_data = self.initialize_performance_tracking()

        with concurrent.futures.ThreadPoolExecutor(max_workers=self.config["scanning"]["max_workers"]) as executor:
            futures = []

            for file_path in files_to_scan:
                if scan_type == "full":
                    futures.append(executor.submit(self.scan_file_comprehensive, file_path))
                elif scan_type == "quick":
                    futures.append(executor.submit(self.scan_file_quick, file_path))
                elif scan_type == "ai_focused":
                    futures.append(executor.submit(self.scan_file_ai_focused, file_path))

            for future in concurrent.futures.as_completed(futures):
                try:
                    result = future.result()
                    if result:
                        findings.extend(result)
                except Exception as e:
                    self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„Ù…Ù„Ù: {e}")

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        ai_insights = self.perform_ai_analysis(findings, files_to_scan)

        # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙƒÙ…
        quantum_assessment = self.assess_quantum_security(findings)

        # ØªØ­Ù„ÙŠÙ„ Web3
        web3_analysis = self.analyze_web3_security(findings)

        # ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙƒÙØ§Ø¡Ø©
        efficiency_report = self.generate_efficiency_report(findings, performance_data)

        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        result = ScanResult(
            scan_id=scan_id,
            timestamp=datetime.now(),
            target_path=target_path,
            total_files=len(files_to_scan),
            scanned_files=len([f for f in futures if f.done()]),
            findings=findings,
            summary=self.generate_summary(findings),
            performance_metrics=performance_data,
            ai_insights=ai_insights,
            quantum_assessment=quantum_assessment,
            web3_analysis=web3_analysis,
            efficiency_report=efficiency_report
        )

        # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        self.save_scan_results(result)

        elapsed_time = time.time() - start_time
        self.logger.info(f"Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ÙØ­Øµ: {scan_id} ÙÙŠ {elapsed_time:.2f} Ø«Ø§Ù†ÙŠØ©")

        return result

    def collect_files(self, target_path: str) -> List[str]:
        """Ø¬Ù…Ø¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±Ø§Ø¯ ÙØ­ØµÙ‡Ø§"""
        files = []
        excluded_paths = set(self.config["scanning"]["excluded_paths"])
        included_extensions = set(self.config["scanning"]["included_extensions"])

        for root, dirs, filenames in os.walk(target_path):
            # Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø­Ø¸ÙˆØ±Ø©
            dirs[:] = [d for d in dirs if d not in excluded_paths]

            for filename in filenames:
                file_path = os.path.join(root, filename)

                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ø¬Ù…
                if os.path.getsize(file_path) > self.config["scanning"]["max_file_size"]:
                    continue

                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ù…ØªØ¯Ø§Ø¯
                if any(filename.endswith(ext) for ext in included_extensions):
                    files.append(file_path)

        return files

    def scan_file_comprehensive(self, file_path: str) -> List[SecurityFinding]:
        """ÙØ­Øµ Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ù„Ù ÙŠØºØ·ÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù€36"""
        findings = []

        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                lines = content.split('\n')

            # ÙØ­Øµ ÙƒÙ„ Ù…Ø¹ÙŠØ§Ø± Ø£Ù…Ù†ÙŠ
            for rule_name, rule_config in self.security_rules.items():
                for pattern in rule_config["patterns"]:
                    matches = re.finditer(pattern, content, re.IGNORECASE | re.MULTILINE)
                    for match in matches:
                        line_number = content[:match.start()].count('\n') + 1
                        code_snippet = self.extract_code_snippet(lines, line_number - 1)

                        finding = SecurityFinding(
                            rule_id=rule_name,
                            severity=rule_config["severity"],
                            category=rule_config["category"],
                            title=rule_config["description"],
                            description=f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Ù…Ø· Ù…Ø´Ø¨ÙˆÙ‡: {pattern}",
                            file_path=file_path,
                            line_number=line_number,
                            code_snippet=code_snippet,
                            recommendation=self.generate_recommendation(rule_name, match.group()),
                            cwe_id=rule_config.get("cwe", ""),
                            confidence=self.calculate_confidence(match, content)
                        )

                        # ØªØ­Ù„ÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø¹ÙŠØ§Ø±
                        if rule_name in ["ai_security", "web3_security", "quantum_crypto"]:
                            finding.ai_analysis = self.perform_detailed_ai_analysis(finding)

                        if rule_name == "quantum_crypto":
                            finding.quantum_safe = self.check_quantum_safety(match.group())

                        if rule_name == "web3_security":
                            finding.web3_compatible = self.check_web3_compatibility(match.group())

                        findings.append(finding)

            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ ÙˆØ§Ù„ÙƒÙØ§Ø¡Ø©
            efficiency_score = self.calculate_efficiency_score(content)
            for finding in findings:
                finding.efficiency_score = efficiency_score

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„Ù…Ù„Ù {file_path}: {e}")

        return findings

    def scan_file_quick(self, file_path: str) -> List[SecurityFinding]:
        """ÙØ­Øµ Ø³Ø±ÙŠØ¹ ÙŠØ±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø­Ø±Ø¬Ø©"""
        findings = []

        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()

            # ÙØ­Øµ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø­Ø±Ø¬Ø© ÙÙ‚Ø·
            critical_rules = {k: v for k, v in self.security_rules.items() if v["severity"] == "CRITICAL"}

            for rule_name, rule_config in critical_rules.items():
                for pattern in rule_config["patterns"]:
                    if re.search(pattern, content, re.IGNORECASE):
                        findings.append(SecurityFinding(
                            rule_id=rule_name,
                            severity=rule_config["severity"],
                            category=rule_config["category"],
                            title=rule_config["description"],
                            description=f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø´ÙƒÙ„Ø© Ø­Ø±Ø¬Ø©: {pattern}",
                            file_path=file_path,
                            line_number=1,
                            code_snippet="",
                            recommendation=self.generate_recommendation(rule_name, pattern)
                        ))

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙØ­Øµ Ø§Ù„Ø³Ø±ÙŠØ¹ Ù„Ù„Ù…Ù„Ù {file_path}: {e}")

        return findings

    def scan_file_ai_focused(self, file_path: str) -> List[SecurityFinding]:
        """ÙØ­Øµ ÙŠØ±ÙƒØ² Ø¹Ù„Ù‰ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ§Ù„Ø£Ù…Ø§Ù† Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
        findings = []

        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()

            # ÙØ­Øµ Ù…Ø¹Ø§ÙŠÙŠØ± AI ÙˆØ§Ù„Ø£Ù…Ø§Ù† Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
            ai_rules = {k: v for k, v in self.security_rules.items()
                       if k in ["ai_security", "web3_security", "quantum_crypto", "devsecops", "efficiency_metrics"]}

            for rule_name, rule_config in ai_rules.items():
                for pattern in rule_config["patterns"]:
                    matches = re.finditer(pattern, content, re.IGNORECASE)
                    for match in matches:
                        finding = SecurityFinding(
                            rule_id=rule_name,
                            severity=rule_config["severity"],
                            category=rule_config["category"],
                            title=rule_config["description"],
                            description=f"ØªØ­Ù„ÙŠÙ„ AI: {pattern}",
                            file_path=file_path,
                            line_number=1,
                            code_snippet=match.group(),
                            recommendation=self.generate_ai_recommendation(rule_name, match.group()),
                            ai_analysis=self.perform_detailed_ai_analysis(None)  # Ø³ÙŠØªÙ… ØªØ­Ø³ÙŠÙ†Ù‡
                        )
                        findings.append(finding)

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙØ­Øµ Ø§Ù„Ù…Ø±ÙƒØ² Ø¹Ù„Ù‰ AI Ù„Ù„Ù…Ù„Ù {file_path}: {e}")

        return findings

    def extract_code_snippet(self, lines: List[str], line_number: int, context: int = 3) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù‚ØªØ·Ù ÙƒÙˆØ¯ Ù…Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚"""
        start = max(0, line_number - context)
        end = min(len(lines), line_number + context + 1)
        return '\n'.join(lines[start:end])

    def calculate_confidence(self, match, content: str) -> float:
        """Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© ÙÙŠ Ø§Ù„Ù†ØªÙŠØ¬Ø©"""
        # Ù…Ù†Ø·Ù‚ Ø¨Ø³ÙŠØ· Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø©
        match_length = len(match.group())
        content_length = len(content)
        match_ratio = match_length / content_length if content_length > 0 else 0

        # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø«Ù‚Ø© Ù„Ù„Ù†Ù…Ø· Ø§Ù„Ø¯Ù‚ÙŠÙ‚
        if match.group().strip() in ["eval(", "innerHTML", "password="]:
            return 0.95

        return min(0.9, match_ratio * 10)

    def generate_recommendation(self, rule_name: str, matched_code: str) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø¥ØµÙ„Ø§Ø­"""
        recommendations = {
            "code_injection": "Ø§Ø³ØªØ®Ø¯Ù… eval() ÙÙ‚Ø· Ù…Ø¹ ÙƒÙˆØ¯ Ù…ÙˆØ«ÙˆÙ‚. ÙÙƒØ± ÙÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… JSON.parse() Ø£Ùˆ Ø¯ÙˆØ§Ù„ Ø¢Ù…Ù†Ø© Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† eval().",
            "xss": "Ø§Ø³ØªØ®Ø¯Ù… textContent Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† innerHTMLØŒ Ø£Ùˆ Ù‚Ù… Ø¨ØªÙ†Ù‚ÙŠØ© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… DOMPurify.",
            "sql_injection": "Ø§Ø³ØªØ®Ø¯Ù… parameterized queries Ø£Ùˆ prepared statements Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† string concatenation.",
            "hardcoded_secrets": "Ø§Ù†Ù‚Ù„ Ø§Ù„Ø³Ø±ÙŠØ§Øª Ø¥Ù„Ù‰ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ø£Ùˆ Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø³Ø±ÙŠØ§Øª.",
            "weak_crypto": "Ø§Ø³ØªØ®Ø¯Ù… Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø­Ø¯ÙŠØ«Ø© Ù…Ø«Ù„ SHA-256ØŒ AES-256ØŒ Ø£Ùˆ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª ÙƒÙ…ÙŠØ© Ø¢Ù…Ù†Ø©.",
            "ai_security": "Ø·Ø¨Ù‚ ØªÙ‚Ù†ÙŠØ§Øª prompt engineering Ø¢Ù…Ù†Ø© ÙˆØªØ­Ù‚Ù‚ Ù…Ù† inputs Ù‚Ø¨Ù„ ØªÙ…Ø±ÙŠØ±Ù‡Ø§ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬.",
            "web3_security": "Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø¯ÙˆØ§Øª ÙØ­Øµ Ø§Ù„Ø¹Ù‚ÙˆØ¯ Ø§Ù„Ø°ÙƒÙŠØ© Ù…Ø«Ù„ Slither Ø£Ùˆ Mythril.",
            "quantum_crypto": "Ø§Ù†ØªÙ‚Ù„ Ø¥Ù„Ù‰ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª PQC Ù…Ø«Ù„ Kyber Ù„Ù„ØªØ´ÙÙŠØ± Ùˆ Dilithium Ù„Ù„ØªÙˆÙ‚ÙŠØ¹."
        }

        return recommendations.get(rule_name, "Ø±Ø§Ø¬Ø¹ Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ© Ù„Ù‡Ø°Ø§ Ø§Ù„Ù†ÙˆØ¹ Ù…Ù† Ø§Ù„Ù…Ø´Ø§ÙƒÙ„.")

    def generate_ai_recommendation(self, rule_name: str, matched_code: str) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø°ÙƒÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… AI"""
        if self.deepseek and self.deepseek.is_server_running():
            try:
                analysis = self.deepseek.analyze_code(matched_code, "general")
                if analysis and "recommendations" in analysis:
                    return analysis["recommendations"][0] if analysis["recommendations"] else self.generate_recommendation(rule_name, matched_code)
            except:
                pass

        return self.generate_recommendation(rule_name, matched_code)

    def perform_ai_analysis(self, findings: List[SecurityFinding], files: List[str]) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
        ai_insights = {
            "overall_risk_assessment": "LOW",
            "critical_findings_analysis": [],
            "patterns_identified": [],
            "recommendations": [],
            "code_quality_score": 0.0,
            "security_maturity_level": "BEGINNER"
        }

        if not self.deepseek or not self.deepseek.is_server_running():
            return ai_insights

        try:
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ø¹Ø§Ù…Ø©
            critical_findings = [f for f in findings if f.severity == "CRITICAL"]
            if len(critical_findings) > 10:
                ai_insights["overall_risk_assessment"] = "CRITICAL"
            elif len(critical_findings) > 5:
                ai_insights["overall_risk_assessment"] = "HIGH"
            elif len(critical_findings) > 0:
                ai_insights["overall_risk_assessment"] = "MEDIUM"

            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
            categories = {}
            for finding in findings:
                categories[finding.category] = categories.get(finding.category, 0) + 1

            ai_insights["patterns_identified"] = [
                {"category": cat, "count": count, "severity": "HIGH" if count > 5 else "MEDIUM"}
                for cat, count in categories.items()
            ]

            # ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„ÙƒÙˆØ¯
            total_files = len(files)
            files_with_findings = len(set(f.file_path for f in findings))
            ai_insights["code_quality_score"] = max(0, 100 - (files_with_findings / total_files * 100))

            # ØªÙ‚ÙŠÙŠÙ… Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù†Ø¶Ø¬ Ø§Ù„Ø£Ù…Ù†ÙŠ
            if ai_insights["code_quality_score"] > 80:
                ai_insights["security_maturity_level"] = "ADVANCED"
            elif ai_insights["code_quality_score"] > 60:
                ai_insights["security_maturity_level"] = "INTERMEDIATE"

        except Exception as e:
            self.logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ: {e}")

        return ai_insights

    def assess_quantum_security(self, findings: List[SecurityFinding]) -> Dict[str, Any]:
        """ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ù…Ø§Ù† Ø§Ù„ÙƒÙ…ÙŠ"""
        quantum_assessment = {
            "quantum_vulnerable_algorithms": [],
            "quantum_safe_recommendations": [],
            "migration_priority": "LOW",
            "estimated_break_time": "DECADE+"
        }

        quantum_vulnerable = [f for f in findings if f.rule_id == "quantum_crypto"]

        if quantum_vulnerable:
            quantum_assessment["quantum_vulnerable_algorithms"] = [
                {
                    "algorithm": f.code_snippet,
                    "risk_level": "HIGH",
                    "replacement": "Kyber-1024" if "rsa" in f.code_snippet.lower() else "AES-256-GCM"
                }
                for f in quantum_vulnerable
            ]
            quantum_assessment["migration_priority"] = "HIGH"
            quantum_assessment["estimated_break_time"] = "MONTHS"

        return quantum_assessment

    def analyze_web3_security(self, findings: List[SecurityFinding]) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø£Ù…Ø§Ù† Web3"""
        web3_analysis = {
            "smart_contract_vulnerabilities": [],
            "defi_risks": [],
            "wallet_security_issues": [],
            "blockchain_integration_risks": []
        }

        web3_findings = [f for f in findings if f.rule_id == "web3_security"]

        for finding in web3_findings:
            if "reentrancy" in finding.code_snippet.lower():
                web3_analysis["smart_contract_vulnerabilities"].append({
                    "type": "REENTRANCY",
                    "severity": "CRITICAL",
                    "description": "Ø¹Ø±Ø¶Ø© Ù„Ù‡Ø¬Ù…Ø§Øª reentrancy"
                })
            elif "access" in finding.code_snippet.lower():
                web3_analysis["smart_contract_vulnerabilities"].append({
                    "type": "ACCESS_CONTROL",
                    "severity": "HIGH",
                    "description": "Ù…Ø´Ø§ÙƒÙ„ ÙÙŠ Ø§Ù„ØªØ­ÙƒÙ… Ø¨Ø§Ù„ÙˆØµÙˆÙ„"
                })

        return web3_analysis

    def generate_efficiency_report(self, findings: List[SecurityFinding], performance_data: Dict) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙƒÙØ§Ø¡Ø©"""
        efficiency_report = {
            "code_complexity_score": 0.0,
            "maintainability_index": 0.0,
            "performance_score": 0.0,
            "resource_utilization": {},
            "optimization_recommendations": []
        }

        # Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙƒÙØ§Ø¡Ø©
        total_findings = len(findings)
        efficiency_findings = [f for f in findings if f.rule_id == "efficiency_metrics"]

        if efficiency_findings:
            efficiency_report["code_complexity_score"] = 100 - (len(efficiency_findings) * 10)
            efficiency_report["maintainability_index"] = max(0, 100 - total_findings)

        # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
        efficiency_report["resource_utilization"] = {
            "cpu_usage": psutil.cpu_percent(interval=1) if HAS_PSUTIL else 0,
            "memory_usage": psutil.virtual_memory().percent if HAS_PSUTIL else 0,
            "disk_usage": psutil.disk_usage('/').percent if HAS_PSUTIL else 0
        }

        return efficiency_report

    def generate_summary(self, findings: List[SecurityFinding]) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""
        summary = {
            "total_findings": len(findings),
            "severity_breakdown": {"CRITICAL": 0, "HIGH": 0, "MEDIUM": 0, "LOW": 0, "INFO": 0},
            "category_breakdown": {},
            "top_vulnerable_files": [],
            "compliance_score": 0.0
        }

        for finding in findings:
            summary["severity_breakdown"][finding.severity] = summary["severity_breakdown"].get(finding.severity, 0) + 1
            summary["category_breakdown"][finding.category] = summary["category_breakdown"].get(finding.category, 0) + 1

        # Ø£ÙƒØ«Ø± Ø§Ù„Ù…Ù„ÙØ§Øª Ø¹Ø±Ø¶Ø©
        file_counts = {}
        for finding in findings:
            file_counts[finding.file_path] = file_counts.get(finding.file_path, 0) + 1

        summary["top_vulnerable_files"] = sorted(file_counts.items(), key=lambda x: x[1], reverse=True)[:10]

        # Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„
        critical_count = summary["severity_breakdown"]["CRITICAL"]
        high_count = summary["severity_breakdown"]["HIGH"]
        total_weighted = critical_count * 10 + high_count * 5 + summary["severity_breakdown"]["MEDIUM"] * 2

        summary["compliance_score"] = max(0, 100 - total_weighted)

        return summary

    def save_scan_results(self, result: ScanResult):
        """Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙØ­Øµ ÙÙŠ Ù…Ø¬Ù„Ø¯Ø§Øª Ù…Ù†ÙØµÙ„Ø©"""
        # Ø­ÙØ¸ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…ÙƒØªØ´ÙØ©
        errors_report = {
            "scan_id": result.scan_id,
            "timestamp": result.timestamp.isoformat(),
            "findings": [
                {
                    "severity": f.severity,
                    "category": f.category,
                    "title": f.title,
                    "file": f.file_path,
                    "line": f.line_number,
                    "description": f.description
                }
                for f in result.findings
            ]
        }

        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡
        self.save_chunked_report(self.directories["errors"] / f"errors_{result.scan_id}.json", errors_report, "errors")

        # Ø­ÙØ¸ Ø®Ø·Ø© Ø§Ù„Ø¥ØµÙ„Ø§Ø­
        fix_plan = self.generate_fix_plan(result.findings)
        self.save_chunked_report(self.directories["fixes"] / f"fix_plan_{result.scan_id}.json", fix_plan, "fixes")

        # Ø­ÙØ¸ ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø¥ØµÙ„Ø§Ø­
        repair_report = self.generate_repair_report(result)
        self.save_chunked_report(self.directories["repairs"] / f"repair_report_{result.scan_id}.json", repair_report, "repairs")

    def save_chunked_report(self, file_path: Path, data: Dict, report_type: str):
        """Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¨Ø´ÙƒÙ„ Ù…Ù‚Ø³Ù…"""
        chunk_size = self.config["reporting"]["chunk_size"]

        if report_type == "errors" and "findings" in data:
            findings = data["findings"]
            for i in range(0, len(findings), chunk_size):
                chunk = findings[i:i + chunk_size]
                chunk_file = file_path.parent / f"{file_path.stem}_part_{i//chunk_size + 1}{file_path.suffix}"

                chunk_data = data.copy()
                chunk_data["findings"] = chunk
                chunk_data["chunk_info"] = {
                    "part": i//chunk_size + 1,
                    "total_parts": (len(findings) + chunk_size - 1) // chunk_size,
                    "items_in_chunk": len(chunk)
                }

                with open(chunk_file, 'w', encoding='utf-8') as f:
                    json.dump(chunk_data, f, ensure_ascii=False, indent=2)

        else:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

    def generate_fix_plan(self, findings: List[SecurityFinding]) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ Ø®Ø·Ø© Ø§Ù„Ø¥ØµÙ„Ø§Ø­"""
        fix_plan = {
            "scan_timestamp": datetime.now().isoformat(),
            "total_issues": len(findings),
            "fix_priorities": {
                "CRITICAL": [],
                "HIGH": [],
                "MEDIUM": [],
                "LOW": []
            },
            "estimated_effort": "UNKNOWN",
            "ai_recommendations": []
        }

        for finding in findings:
            fix_item = {
                "file": finding.file_path,
                "line": finding.line_number,
                "issue": finding.title,
                "recommendation": finding.recommendation,
                "effort": self.estimate_fix_effort(finding)
            }

            fix_plan["fix_priorities"][finding.severity].append(fix_item)

        # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„Ø¬Ù‡Ø¯ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
        total_effort = sum(len(items) * (4 if sev == "CRITICAL" else 3 if sev == "HIGH" else 2 if sev == "MEDIUM" else 1)
                          for sev, items in fix_plan["fix_priorities"].items())
        fix_plan["estimated_effort"] = f"{total_effort} Ø³Ø§Ø¹Ø§Øª"

        return fix_plan

    def generate_repair_report(self, result: ScanResult) -> Dict[str, Any]:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø¥ØµÙ„Ø§Ø­"""
        repair_report = {
            "scan_id": result.scan_id,
            "repair_timestamp": datetime.now().isoformat(),
            "summary": result.summary,
            "ai_insights": result.ai_insights,
            "quantum_assessment": result.quantum_assessment,
            "web3_analysis": result.web3_analysis,
            "efficiency_report": result.efficiency_report,
            "performance_metrics": result.performance_metrics,
            "repair_status": "PLANNED",
            "automated_fixes_applied": 0,
            "manual_fixes_required": len(result.findings)
        }

        return repair_report

    def estimate_fix_effort(self, finding: SecurityFinding) -> str:
        """ØªÙ‚Ø¯ÙŠØ± Ø¬Ù‡Ø¯ Ø§Ù„Ø¥ØµÙ„Ø§Ø­"""
        effort_map = {
            "CRITICAL": "4-8 Ø³Ø§Ø¹Ø§Øª",
            "HIGH": "2-4 Ø³Ø§Ø¹Ø§Øª",
            "MEDIUM": "1-2 Ø³Ø§Ø¹Ø§Øª",
            "LOW": "30 Ø¯Ù‚ÙŠÙ‚Ø© - 1 Ø³Ø§Ø¹Ø©"
        }
        return effort_map.get(finding.severity, "1 Ø³Ø§Ø¹Ø©")

    def check_quantum_safety(self, code: str) -> bool:
        """ÙØ­Øµ Ø§Ù„Ø£Ù…Ø§Ù† Ø§Ù„ÙƒÙ…ÙŠ"""
        vulnerable_patterns = ["rsa.*1024", "ecdsa.*p256", "sha.*1", "md5"]
        return not any(re.search(pattern, code, re.IGNORECASE) for pattern in vulnerable_patterns)

    def check_web3_compatibility(self, code: str) -> bool:
        """ÙØ­Øµ Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Web3"""
        web3_patterns = ["web3", "ethereum", "smart.contract", "solidity"]
        return any(re.search(pattern, code, re.IGNORECASE) for pattern in web3_patterns)

    def calculate_efficiency_score(self, content: str) -> float:
        """Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø± Ø§Ù„ÙƒÙØ§Ø¡Ø©"""
        # Ù…Ù†Ø·Ù‚ Ø¨Ø³ÙŠØ· Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ÙƒÙØ§Ø¡Ø©
        lines = len(content.split('\n'))
        functions = len(re.findall(r'def\s+\w+', content))
        classes = len(re.findall(r'class\s+\w+', content))

        # Ø­Ø³Ø§Ø¨ ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„ÙƒÙˆØ¯
        complexity = min(100, (functions * 2 + classes * 5 + lines / 10))
        return max(0, 100 - complexity)

    def perform_detailed_ai_analysis(self, finding: SecurityFinding = None) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ù…ÙØµÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… AI"""
        if not self.deepseek or not self.deepseek.is_server_running():
            return {"analysis": "AI analysis not available", "confidence": 0.0}

        try:
            # Ù…Ù†Ø·Ù‚ ØªØ­Ù„ÙŠÙ„ AI Ù…ÙØµÙ„
            return {
                "analysis_type": "DETAILED_SECURITY",
                "confidence": 0.85,
                "insights": ["Pattern detected", "Potential vulnerability"],
                "recommendations": ["Apply security best practices", "Review code patterns"]
            }
        except:
            return {"analysis": "Analysis failed", "confidence": 0.0}

    def initialize_performance_tracking(self) -> Dict[str, Any]:
        """ØªÙ‡ÙŠØ¦Ø© ØªØªØ¨Ø¹ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        return {
            "start_time": time.time(),
            "cpu_usage_start": psutil.cpu_percent() if HAS_PSUTIL else 0,
            "memory_usage_start": psutil.virtual_memory().percent if HAS_PSUTIL else 0,
            "gpu_usage": [],
            "files_processed": 0,
            "patterns_matched": 0
        }

    def run_dashboard_server(self, host: str = "localhost", port: int = 8080):
        """ØªØ´ØºÙŠÙ„ Ø®Ø§Ø¯Ù… Ø§Ù„Ø¯Ø§Ø´ Ø¨ÙˆØ±Ø¯"""
        try:
            from dashboard_server import DashboardServer
            server = DashboardServer(self, host, port)
            server.run()
        except ImportError:
            self.logger.error("Dashboard server not available")
        except Exception as e:
            self.logger.error(f"Error starting dashboard server: {e}")

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    parser = argparse.ArgumentParser(description="DeepSeek Ultimate Security Scanner v5.0")
    parser.add_argument("target", help="Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ù…Ø±Ø§Ø¯ ÙØ­ØµÙ‡")
    parser.add_argument("--type", choices=["full", "quick", "ai_focused"], default="full",
                       help="Ù†ÙˆØ¹ Ø§Ù„ÙØ­Øµ")
    parser.add_argument("--config", help="Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    parser.add_argument("--dashboard", action="store_true", help="ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¯Ø§Ø´ Ø¨ÙˆØ±Ø¯")
    parser.add_argument("--dashboard-port", type=int, default=8080, help="Ù…Ù†ÙØ° Ø§Ù„Ø¯Ø§Ø´ Ø¨ÙˆØ±Ø¯")

    args = parser.parse_args()

    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø§Ø³Ø­
    scanner = DeepSeekUltimateScanner(args.config)

    if args.dashboard:
        # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¯Ø§Ø´ Ø¨ÙˆØ±Ø¯
        scanner.run_dashboard_server(port=args.dashboard_port)
    else:
        # ØªØ´ØºÙŠÙ„ Ø§Ù„ÙØ­Øµ
        result = scanner.scan_project(args.target, args.type)

        print(f"\nğŸ¯ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙØ­Øµ Ø§Ù„Ø´Ø§Ù…Ù„:")
        print(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª: {result.total_files}")
        print(f"ğŸ” Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙØ­ÙˆØµØ©: {result.scanned_files}")
        print(f"âš ï¸  Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {result.summary['total_findings']}")
        print(f"ğŸš¨ Ø§Ù„Ø­Ø±Ø¬Ø©: {result.summary['severity_breakdown']['CRITICAL']}")
        print(f"âš¡ Ø§Ù„Ø¹Ø§Ù„ÙŠØ©: {result.summary['severity_breakdown']['HIGH']}")
        print(f"ğŸ“ ØªÙ‚Ø§Ø±ÙŠØ± Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ: {scanner.directories['reports']}")

if __name__ == "__main__":
    import argparse
    main()